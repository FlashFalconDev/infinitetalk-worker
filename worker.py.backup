"""
InfiniteTalk Worker - v7.3.3
ä¿®æ­£ï¼šå¿ƒè·³ç”¨ /ai/apiï¼Œå…¶ä»–ç”¨ /aigen/api
"""
import requests
import json
import os
import uuid
import time
import logging
import socket
import threading
from datetime import datetime

from dotenv import load_dotenv
load_dotenv()

from model_service import get_model_service

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class InfiniteTalkWorker:
    def __init__(self):
        # ===== API é…ç½® =====
        self.primary_base = "https://www.flashfalcon.info"
        self.backup_base = "https://host.flashfalcon.info"
        self.current_base = self.primary_base
        
        # å¤±æ•—è¨ˆæ•¸å™¨
        self.primary_fail_count = 0
        self.max_fails_before_switch = 2
        
        # Token
        self.worker_token = os.getenv('INFINITETALK_WORKER_TOKEN')
        
        if not self.worker_token:
            logger.error("=" * 70)
            logger.error("âŒ ç¼ºå°‘ç’°å¢ƒè®Šæ•¸: INFINITETALK_WORKER_TOKEN")
            logger.error("=" * 70)
            raise ValueError("Missing INFINITETALK_WORKER_TOKEN")
        
        # Worker è³‡è¨Š
        self.worker_id = self._generate_worker_id()
        self.worker_version = "7.3.3"
        
        # ç›®éŒ„è¨­å®š
        self.temp_dir = "temp_downloads"
        self.output_dir = "outputs"
        os.makedirs(self.temp_dir, exist_ok=True)
        os.makedirs(self.output_dir, exist_ok=True)
        
        # æª¢æŸ¥ GPU ç›£æ§
        self.gpu_monitoring_available = self._check_gpu_monitoring()
        
        # åˆå§‹åŒ–
        logger.info("=" * 70)
        logger.info("ğŸš€ åˆå§‹åŒ– InfiniteTalk Worker v7.3.3")
        logger.info(f"ğŸ†” Worker ID: {self.worker_id}")
        logger.info(f"ğŸ”‘ Token: {self.worker_token[:10]}...{self.worker_token[-10:]}")
        logger.info(f"ğŸŒ ä¸» API: {self.primary_base}")
        logger.info(f"ğŸ”„ å‚™ç”¨ API: {self.backup_base}")
        logger.info(f"ğŸ“Š GPU ç›£æ§: {'âœ… å·²å•Ÿç”¨' if self.gpu_monitoring_available else 'âš ï¸  åŸºæœ¬æ¨¡å¼'}")
        logger.info("=" * 70)
        
        # æ¸¬è©¦é€£ç·š
        if not self._test_connection():
            raise ConnectionError("âŒ ç„¡æ³•é€£æ¥åˆ°ä¼ºæœå™¨")
        
        # è¼‰å…¥æ¨¡å‹
        logger.info("ğŸ“¥ è¼‰å…¥æ¨¡å‹ï¼ˆåªåŸ·è¡Œä¸€æ¬¡ï¼‰...")
        self.model_service = get_model_service()
        
        # å•Ÿå‹•å¿ƒè·³ç·šç¨‹
        self._start_heartbeat_thread()
        
        logger.info("=" * 70)
        logger.info("âœ… Worker æº–å‚™å°±ç·’!")
        logger.info("=" * 70)
    
    def _get_api_endpoints(self):
        """âœ… å‹•æ…‹ç²å– API ç«¯é»ï¼ˆå¿ƒè·³ç”¨ /ai/apiï¼Œå…¶ä»–ç”¨ /aigen/apiï¼‰"""
        return {
            'heartbeat': f"{self.current_base}/ai/api/worker/heartbeat",        # /ai/api
            'task': f"{self.current_base}/aigen/api/pending_task/",             # /aigen/api
            'result': f"{self.current_base}/aigen/api/task_result/",            # /aigen/api
            'upload': f"{self.current_base}/api/save_file/"                     # /api
        }
    
    def _switch_to_backup(self):
        """åˆ‡æ›åˆ°å‚™ç”¨ API"""
        if self.current_base == self.primary_base:
            logger.warning("âš ï¸  ä¸» API é€£ç·šå¤±æ•—ï¼Œåˆ‡æ›åˆ°å‚™ç”¨ API")
            self.current_base = self.backup_base
            logger.info(f"ğŸ”„ ç•¶å‰ä½¿ç”¨: {self.current_base}")
    
    def _switch_to_primary(self):
        """åˆ‡å›ä¸» API"""
        if self.current_base == self.backup_base:
            logger.info("âœ… ä¸» API æ¢å¾©æ­£å¸¸ï¼Œåˆ‡å›ä¸» API")
            self.current_base = self.primary_base
            logger.info(f"ğŸ”„ ç•¶å‰ä½¿ç”¨: {self.current_base}")
    
    def _make_request(self, method, endpoint_key, **kwargs):
        """çµ±ä¸€çš„è«‹æ±‚æ–¹æ³•ï¼ˆåªæœ‰é€£ç·šå¤±æ•—æ‰åˆ‡æ›ï¼‰"""
        endpoints = self._get_api_endpoints()
        url = endpoints[endpoint_key]
        
        try:
            if method.upper() == 'GET':
                response = requests.get(url, **kwargs)
            else:
                response = requests.post(url, **kwargs)
            
            # åªè¦æœ‰éŸ¿æ‡‰ï¼Œéƒ½ç®—é€£ç·šæˆåŠŸ
            if self.primary_fail_count > 0:
                self.primary_fail_count = 0
                logger.debug(f"âœ… API é€£ç·šæ­£å¸¸ï¼Œé‡ç½®å¤±æ•—è¨ˆæ•¸")
            
            # å¦‚æœç•¶å‰ä½¿ç”¨å‚™ç”¨ APIï¼Œä¸”ä¸» API å·²æ¢å¾©ï¼Œåˆ‡å›ä¸» API
            if self.current_base == self.backup_base:
                self._switch_to_primary()
            
            return response
        
        except (requests.exceptions.ConnectionError, 
                requests.exceptions.Timeout,
                requests.exceptions.RequestException) as e:
            logger.warning(f"âš ï¸  é€£ç·šå¤±æ•—: {type(e).__name__}")
            
            # åªæœ‰ä¸» API å¤±æ•—æ‰è¨ˆæ•¸
            if self.current_base == self.primary_base:
                self.primary_fail_count += 1
                logger.warning(f"âš ï¸  ä¸» API é€£ç·šå¤±æ•—æ¬¡æ•¸: {self.primary_fail_count}/{self.max_fails_before_switch}")
                
                # é”åˆ°é–¾å€¼ï¼Œåˆ‡æ›åˆ°å‚™ç”¨
                if self.primary_fail_count >= self.max_fails_before_switch:
                    self._switch_to_backup()
                    self.primary_fail_count = 0
                    
                    # ç”¨å‚™ç”¨ API é‡è©¦
                    logger.info("ğŸ”„ ä½¿ç”¨å‚™ç”¨ API é‡è©¦...")
                    endpoints = self._get_api_endpoints()
                    url = endpoints[endpoint_key]
                    
                    try:
                        if method.upper() == 'GET':
                            response = requests.get(url, **kwargs)
                        else:
                            response = requests.post(url, **kwargs)
                        return response
                    except Exception as e2:
                        logger.error(f"âŒ å‚™ç”¨ API ä¹Ÿé€£ç·šå¤±æ•—: {e2}")
                        return None
            
            return None
    
    def _generate_worker_id(self):
        """ç”Ÿæˆ Worker ID"""
        if os.getenv('WORKER_ID'):
            return os.getenv('WORKER_ID')
        
        hostname = socket.gethostname()
        short_uuid = str(uuid.uuid4())[:8]
        return f"{hostname}-{short_uuid}"
    
    def _check_gpu_monitoring(self):
        """æª¢æŸ¥ GPU ç›£æ§"""
        try:
            import pynvml
            pynvml.nvmlInit()
            device_count = pynvml.nvmlDeviceGetCount()
            pynvml.nvmlShutdown()
            logger.info(f"âœ… GPU ç›£æ§å·²å•Ÿç”¨ (åµæ¸¬åˆ° {device_count} å€‹ GPU)")
            return True
        except ImportError:
            logger.warning("âš ï¸  æœªå®‰è£ nvidia-ml-py3ï¼Œä½¿ç”¨åŸºæœ¬ GPU ç›£æ§")
            return False
        except Exception as e:
            logger.warning(f"âš ï¸  ç„¡æ³•åˆå§‹åŒ– GPU ç›£æ§: {e}")
            return False
    
    def _get_auth_headers(self):
        """ç²å–èªè­‰ Headers"""
        return {
            'Authorization': f'Bearer {self.worker_token}',
            'Content-Type': 'application/json'
        }
    
    def _get_system_info(self):
        """ç²å–ç³»çµ±è³‡è¨Š"""
        info = {
            'hostname': socket.gethostname(),
            'version': self.worker_version
        }
        
        try:
            import torch
            if torch.cuda.is_available():
                gpu_props = torch.cuda.get_device_properties(0)
                info['gpu_info'] = {
                    'name': torch.cuda.get_device_name(0),
                    'count': torch.cuda.device_count(),
                    'total_memory_gb': round(gpu_props.total_memory / 1024**3, 2),
                    'cuda_version': str(torch.version.cuda),
                    'pytorch_version': str(torch.__version__)
                }
                
                if self.gpu_monitoring_available:
                    try:
                        import pynvml
                        pynvml.nvmlInit()
                        driver_version = pynvml.nvmlSystemGetDriverVersion()
                        if isinstance(driver_version, bytes):
                            driver_version = driver_version.decode('utf-8')
                        info['gpu_info']['driver_version'] = driver_version
                        pynvml.nvmlShutdown()
                    except:
                        pass
        except Exception as e:
            logger.warning(f"ç„¡æ³•ç²å– GPU è³‡è¨Š: {e}")
        
        return info
    
    def _get_gpu_stats(self):
        """ç²å– GPU ç‹€æ…‹"""
        stats = {}
        
        try:
            import torch
            if not torch.cuda.is_available():
                return stats
            
            allocated = torch.cuda.memory_allocated(0) / 1024**3
            reserved = torch.cuda.memory_reserved(0) / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            
            stats['gpu_memory_used'] = round(allocated, 2)
            stats['gpu_memory_reserved'] = round(reserved, 2)
            stats['gpu_memory_total'] = round(total, 2)
            stats['gpu_memory_utilization'] = round((allocated / total) * 100, 2)
            
            if self.gpu_monitoring_available:
                try:
                    import pynvml
                    pynvml.nvmlInit()
                    
                    handle = pynvml.nvmlDeviceGetHandleByIndex(0)
                    
                    util = pynvml.nvmlDeviceGetUtilizationRates(handle)
                    stats['gpu_utilization'] = int(util.gpu)
                    stats['gpu_memory_controller_utilization'] = int(util.memory)
                    
                    temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
                    stats['gpu_temperature'] = int(temp)
                    
                    try:
                        power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0
                        power_limit = pynvml.nvmlDeviceGetPowerManagementLimit(handle) / 1000.0
                        stats['gpu_power_usage'] = round(power, 2)
                        stats['gpu_power_limit'] = round(power_limit, 2)
                        stats['gpu_power_utilization'] = round((power / power_limit) * 100, 2)
                    except:
                        pass
                    
                    try:
                        clock_graphics = pynvml.nvmlDeviceGetClockInfo(handle, pynvml.NVML_CLOCK_GRAPHICS)
                        clock_memory = pynvml.nvmlDeviceGetClockInfo(handle, pynvml.NVML_CLOCK_MEM)
                        stats['gpu_clock_graphics_mhz'] = int(clock_graphics)
                        stats['gpu_clock_memory_mhz'] = int(clock_memory)
                    except:
                        pass
                    
                    try:
                        fan_speed = pynvml.nvmlDeviceGetFanSpeed(handle)
                        stats['gpu_fan_speed'] = int(fan_speed)
                    except:
                        pass
                    
                    try:
                        processes = pynvml.nvmlDeviceGetComputeRunningProcesses(handle)
                        stats['gpu_process_count'] = len(processes)
                    except:
                        pass
                    
                    pynvml.nvmlShutdown()
                    
                except Exception as e:
                    logger.debug(f"è©³ç´° GPU ç›£æ§å¤±æ•—: {e}")
            
        except Exception as e:
            logger.debug(f"ç²å– GPU ç‹€æ…‹å¤±æ•—: {e}")
        
        return stats
    
    def _test_connection(self):
        """æ¸¬è©¦é€£ç·š"""
        try:
            logger.info("ğŸ”Œ æ¸¬è©¦é€£ç·š...")
            
            headers = self._get_auth_headers()
            data = {
                'worker_id': self.worker_id,
                'status': 'online',
                'timestamp': datetime.now().isoformat(),
                **self._get_system_info()
            }
            
            response = self._make_request('POST', 'heartbeat', json=data, headers=headers, timeout=10)
            
            if response and response.status_code == 200:
                result = response.json()
                if result.get('success'):
                    logger.info("âœ… é€£ç·šæˆåŠŸ")
                    logger.info(f"   ä½¿ç”¨ API: {self.current_base}")
                    if 'data' in result and 'worker_name' in result['data']:
                        logger.info(f"   å¾Œç«¯è­˜åˆ¥ç‚º: {result['data']['worker_name']}")
                    return True
            
            logger.error("âŒ é€£ç·šå¤±æ•—")
            return False
                
        except Exception as e:
            logger.error(f"âŒ é€£ç·šæ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def _send_heartbeat(self):
        """ç™¼é€å¿ƒè·³"""
        try:
            headers = self._get_auth_headers()
            
            data = {
                'worker_id': self.worker_id,
                'status': 'online',
                'timestamp': datetime.now().isoformat(),
                'version': self.worker_version,
                **self._get_gpu_stats()
            }
            
            response = self._make_request('POST', 'heartbeat', json=data, headers=headers, timeout=10)
            
            if response and response.status_code == 200:
                logger.debug(f"ğŸ’“ å¿ƒè·³ç™¼é€æˆåŠŸ ({self.current_base})")
                return True
            elif response and response.status_code == 401:
                logger.error(f"âŒ Token å·²å¤±æ•ˆ")
                return False
            else:
                logger.warning(f"âš ï¸  å¿ƒè·³éŸ¿æ‡‰ç•°å¸¸: {response.status_code if response else 'None'}")
                return False
                
        except Exception as e:
            logger.warning(f"âš ï¸  å¿ƒè·³éŒ¯èª¤: {e}")
            return False
    
    def _heartbeat_loop(self):
        """å¿ƒè·³å¾ªç’°"""
        while True:
            try:
                self._send_heartbeat()
                time.sleep(60)
            except Exception as e:
                logger.error(f"å¿ƒè·³å¾ªç’°éŒ¯èª¤: {e}")
                time.sleep(60)
    
    def _start_heartbeat_thread(self):
        """å•Ÿå‹•å¿ƒè·³ç·šç¨‹"""
        heartbeat_thread = threading.Thread(
            target=self._heartbeat_loop,
            daemon=True,
            name="HeartbeatThread"
        )
        heartbeat_thread.start()
        logger.info("ğŸ’“ å¿ƒè·³ç·šç¨‹å·²å•Ÿå‹•ï¼ˆæ¯ 60 ç§’ï¼‰")
    
    def fetch_task(self):
        """ç²å–å¾…è™•ç†ä»»å‹™"""
        try:
            logger.info("æŸ¥è©¢å¾…è™•ç†ä»»å‹™...")
            
            params = {'model_code': 'InfiniteTalk_S2V'}
            headers = self._get_auth_headers()
            
            response = self._make_request('GET', 'task', params=params, headers=headers, timeout=30)
            
            if not response:
                return []
            
            if response.status_code == 401:
                logger.error("âŒ Token å·²å¤±æ•ˆ")
                return []
            
            if response.status_code == 403:
                result = response.json()
                logger.error(f"âŒ {result.get('error', 'Permission denied')}")
                return []
            
            if response.status_code == 200:
                result = response.json()
                
                if result is None or not isinstance(result, dict):
                    return []
                
                if not result.get("success"):
                    return []
                
                if "data" not in result:
                    return []
                
                data = result["data"]
                
                if data is None or not isinstance(data, dict):
                    return []
                
                if "Generation_Video_task" not in data:
                    return []
                
                tasks = data["Generation_Video_task"]
                
                if tasks is None or not isinstance(tasks, list):
                    return []
                
                if len(tasks) > 0:
                    logger.info(f"âœ… ç²å–åˆ° {len(tasks)} å€‹ä»»å‹™ (ä¾†è‡ª {self.current_base})")
                    return tasks
                
                return []
            else:
                logger.warning(f"âš ï¸  ç²å–ä»»å‹™éŸ¿æ‡‰ç•°å¸¸: HTTP {response.status_code}")
                return []
                
        except Exception as e:
            logger.error(f"ç²å–ä»»å‹™éŒ¯èª¤: {e}")
            return []
    
    def download_file(self, url, save_path):
        """ä¸‹è¼‰æª”æ¡ˆ"""
        try:
            logger.info(f"ğŸ“¥ ä¸‹è¼‰: {url}")
            response = requests.get(url, timeout=300, stream=True)
            
            if response.status_code == 200:
                with open(save_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                logger.info(f"âœ… ä¸‹è¼‰å®Œæˆ: {save_path}")
                return True
            else:
                logger.error(f"ä¸‹è¼‰å¤±æ•—: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"ä¸‹è¼‰éŒ¯èª¤: {e}")
            return False
    
    def generate_video(self, image_path, audio_path, prompt, task_id, quality='balanced'):
        """ç”Ÿæˆå½±ç‰‡"""
        try:
            output_path = os.path.join(self.output_dir, f"{task_id}_output")
            
            start_time = time.time()
            
            final_path = self.model_service.generate(
                image_path=image_path,
                audio_path=audio_path,
                prompt=prompt,
                output_path=output_path,
                quality=quality
            )
            
            generation_time = int((time.time() - start_time) / 60)
            
            return final_path, generation_time
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤±æ•—: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None, 0
    
    def upload_video(self, video_path, task_id):
        """ä¸Šå‚³å½±ç‰‡"""
        try:
            logger.info(f"ğŸ“¤ ä¸Šå‚³å½±ç‰‡: {video_path}")
            
            with open(video_path, "rb") as f:
                files = {"file": (f"{task_id}.mp4", f, "video/mp4")}
                
                # âœ… æ·»åŠ èªè­‰ Headers
                headers = {'Authorization': f'Bearer {self.worker_token}'}
                
                endpoints = self._get_api_endpoints()
                response = requests.post(endpoints['upload'], files=files, headers=headers, timeout=600)
                
                if response.status_code == 200:
                    result = response.json()
                    
                    if result.get("ok"):
                        video_url = result["data"]["url"]
                        logger.info(f"âœ… ä¸Šå‚³æˆåŠŸ: {video_url}")
                        return video_url
                    else:
                        raise Exception(f"ä¸Šå‚³å¤±æ•—: {result}")
                else:
                    raise Exception(f"HTTP éŒ¯èª¤: {response.status_code}")
                    
        except Exception as e:
            logger.error(f"ä¸Šå‚³éŒ¯èª¤: {e}")
            return None
    
    def report_result(self, task_pk, video_url, quality, generation_time):
        """å›å ±çµæœ"""
        try:
            logger.info(f"ğŸ“® å›å ±çµæœ - ä»»å‹™PK: {task_pk}")
            
            data = {
                "video_generation_image_audio_pk": task_pk,
                "video_url": video_url,
                "worker_id": self.worker_id,
                "quality": quality,
                "generation_time": generation_time
            }
            
            headers = self._get_auth_headers()
            
            response = self._make_request('POST', 'result', json=data, headers=headers, timeout=30)
            
            if response and response.status_code == 200:
                result = response.json()
                
                if result.get("success"):
                    logger.info("âœ… çµæœå›å ±æˆåŠŸ")
                    return True
                else:
                    logger.error(f"âŒ å›å ±å¤±æ•—: {result.get('error')}")
                    return False
            else:
                logger.error(f"âŒ HTTP éŒ¯èª¤: {response.status_code if response else 'None'}")
                return False
                
        except Exception as e:
            logger.error(f"å›å ±éŒ¯èª¤: {e}")
            return False
    
    def cleanup(self, task_id):
        """æ¸…ç†è‡¨æ™‚æª”æ¡ˆ"""
        try:
            files_to_delete = [
                os.path.join(self.temp_dir, f"{task_id}_image.jpg"),
                os.path.join(self.temp_dir, f"{task_id}_audio.wav"),
                os.path.join(self.output_dir, f"{task_id}_output.mp4")
            ]
            
            for file_path in files_to_delete:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    logger.info(f"ğŸ—‘ï¸  å·²åˆªé™¤: {file_path}")
                    
        except Exception as e:
            logger.error(f"æ¸…ç†éŒ¯èª¤: {e}")
    
    def process_task(self, task):
        """è™•ç†ä»»å‹™"""
        task_id = str(uuid.uuid4())
        task_pk = task["video_generation_image_audio_pk"]
        quality = task.get("quality", "balanced")
        
        logger.info("=" * 70)
        logger.info(f"ğŸ¬ è™•ç†ä»»å‹™ PK: {task_pk}")
        logger.info(f"ğŸ“ Prompt: {task['prompt']}")
        logger.info(f"ğŸ¨ Quality: {quality}")
        logger.info("=" * 70)
        
        try:
            image_path = os.path.join(self.temp_dir, f"{task_id}_image.jpg")
            audio_path = os.path.join(self.temp_dir, f"{task_id}_audio.wav")
            
            if not self.download_file(task["image_model_url"], image_path):
                raise Exception("ä¸‹è¼‰åœ–ç‰‡å¤±æ•—")
            
            if not self.download_file(task["sound_model_url"], audio_path):
                raise Exception("ä¸‹è¼‰éŸ³é »å¤±æ•—")
            
            video_path, generation_time = self.generate_video(
                image_path, audio_path, task["prompt"], task_id, quality
            )
            
            if not video_path:
                raise Exception("ç”Ÿæˆå½±ç‰‡å¤±æ•—")
            
            video_url = self.upload_video(video_path, task_id)
            
            if not video_url:
                raise Exception("ä¸Šå‚³å½±ç‰‡å¤±æ•—")
            
            if not self.report_result(task_pk, video_url, quality, generation_time):
                raise Exception("å›å ±çµæœå¤±æ•—")
            
            self.cleanup(task_id)
            
            logger.info("=" * 70)
            logger.info("âœ… ä»»å‹™å®Œæˆ!")
            logger.info(f"   å“è³ª: {quality}")
            logger.info(f"   è€—æ™‚: {generation_time} åˆ†é˜")
            logger.info("=" * 70)
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä»»å‹™å¤±æ•—: {e}")
            self.cleanup(task_id)
            return False
    
    def run(self, poll_interval=30):
        """é‹è¡Œ Worker"""
        logger.info("=" * 70)
        logger.info("ğŸ¤– InfiniteTalk Worker é‹è¡Œä¸­...")
        logger.info(f"ğŸ†” Worker ID: {self.worker_id}")
        logger.info(f"ğŸŒ ä¸» API: {self.primary_base}")
        logger.info(f"ğŸ”„ å‚™ç”¨ API: {self.backup_base}")
        logger.info(f"â±ï¸  è¼ªè©¢é–“éš”: {poll_interval} ç§’")
        logger.info("=" * 70)
        
        while True:
            try:
                tasks = self.fetch_task()
                
                if tasks:
                    for task in tasks:
                        self.process_task(task)
                else:
                    logger.info(f"ğŸ’¤ ç­‰å¾… {poll_interval} ç§’...")
                    time.sleep(poll_interval)
                    
            except KeyboardInterrupt:
                logger.info("â›” æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œåœæ­¢ worker")
                break
            except Exception as e:
                logger.error(f"é‹è¡ŒéŒ¯èª¤: {e}")
                import traceback
                logger.error(traceback.format_exc())
                time.sleep(poll_interval)

if __name__ == "__main__":
    worker = InfiniteTalkWorker()
    worker.run(poll_interval=30)
