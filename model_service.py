"""
InfiniteTalk æ¨¡å‹æœå‹™ - æœ€çµ‚å„ªåŒ–ç‰ˆ v7.1
æ”¯æ´å­—ä¸²é è¨­é…ç½® + å­—å…¸è‡ªè¨‚é…ç½®
"""
import torch
import os
import sys
import logging
import soundfile as sf
import numpy as np
import subprocess
from types import SimpleNamespace

sys.path.insert(0, '/workspace/InfiniteTalk')

import wan
from src.audio_analysis.wav2vec2 import Wav2Vec2Model
from transformers import Wav2Vec2FeatureExtractor
from wan.utils.multitalk_utils import save_video_ffmpeg
from wan.configs import WAN_CONFIGS
from generate_infinitetalk import audio_prepare_single, get_embedding

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

QUALITY_PRESETS = {
    'ultra_fast': {
        'resolution': '480',
        'sampling_steps': 3,
        'motion_frame': 3,
        'mode': 'streaming',
        'est_time': '12åˆ†',
        'description': 'âš¡âš¡âš¡ è¶…å¿«é€Ÿ 480P (3æ­¥+3å¹€ 12åˆ†) - æ¥µé™é€Ÿåº¦æ¸¬è©¦'
    },
    'turbo': {
        'resolution': '480',
        'sampling_steps': 4,
        'motion_frame': 4,
        'mode': 'streaming',
        'est_time': '18åˆ†',
        'description': 'âš¡âš¡ æ¥µé€Ÿ 480P (4æ­¥+4å¹€ 18åˆ†) - å¿«é€Ÿé è¦½'
    },
    'fast': {
        'resolution': '480',
        'sampling_steps': 6,
        'motion_frame': 7,
        'mode': 'streaming',
        'est_time': '35åˆ†',
        'description': 'âš¡ å¿«é€Ÿ 480P (6æ­¥+7å¹€ 35åˆ†) - æ¸¬è©¦æ¨è–¦ â˜…'
    },
    'balanced': {
        'resolution': '480',
        'sampling_steps': 7,
        'motion_frame': 8,
        'mode': 'streaming',
        'est_time': '50åˆ†',
        'description': 'â­â­â­â­â­ æ—¥å¸¸æ¨è–¦ 480P (7æ­¥+8å¹€ 50åˆ†) - æœ€ä½³å¹³è¡¡ â˜…â˜…â˜…'
    },
    'high': {
        'resolution': '480',
        'sampling_steps': 8,
        'motion_frame': 9,
        'mode': 'streaming',
        'est_time': '70åˆ†',
        'description': 'â­â­â­â­ é«˜å“è³ª 480P (8æ­¥+9å¹€ 70åˆ†) - ç´°ç¯€è±å¯Œ'
    },
    'ultra': {
        'resolution': '720',
        'sampling_steps': 8,
        'motion_frame': 9,
        'mode': 'streaming',
        'est_time': '120åˆ†',
        'description': 'â­â­ æ¥µè‡´å“è³ª 720P (8æ­¥+9å¹€ 120åˆ†) - åŸç”Ÿé«˜æ¸…'
    }
}

class InfiniteTalkModelService:
    def __init__(self, 
                 ckpt_dir='weights/Wan2.1-I2V-14B-480P',
                 wav2vec_dir='weights/chinese-wav2vec2-base',
                 infinitetalk_dir='weights/InfiniteTalk/single/infinitetalk.safetensors',
                 lora_dir='weights/Wan2.1_I2V_14B_FusionX_LoRA.safetensors',
                 device='cuda'):
        
        self.ckpt_dir = ckpt_dir
        self.wav2vec_dir = wav2vec_dir
        self.infinitetalk_dir = infinitetalk_dir
        self.lora_dir = lora_dir
        self.device = device
        
        self.loaded = False
        self.wan_i2v = None
        self.wav2vec_feature_extractor = None
        self.audio_encoder = None
        
        lora_exists = os.path.exists(lora_dir)
        logger.info("=" * 80)
        logger.info(f"ğŸ¨ LoRA é…ç½®:")
        logger.info(f"   è·¯å¾‘: {lora_dir}")
        if lora_exists:
            size_mb = os.path.getsize(lora_dir) / (1024*1024)
            logger.info(f"   ç‹€æ…‹: âœ… å·²è¼‰å…¥")
            logger.info(f"   å¤§å°: {size_mb:.1f} MB")
        else:
            logger.info(f"   ç‹€æ…‹: âšª æœªä½¿ç”¨ï¼ˆé¸ç”¨åŠŸèƒ½ï¼Œä¸å½±éŸ¿åŸºç¤ç”Ÿæˆï¼‰")
        logger.info("=" * 80)
        
        logger.info("ğŸ“Š å“è³ªæ–¹æ¡ˆ (6 æª”ç²¾é¸ - æœ€çµ‚å„ªåŒ–ç‰ˆ v7.1)")
        logger.info("")
        logger.info("   âš¡ å¿«é€Ÿæ¸¬è©¦ (é™ä½ steps/frames):")
        logger.info("   â”œâ”€ Ultra Fast - 12åˆ†  (3æ­¥+3å¹€)           æ¥µé™é€Ÿåº¦")
        logger.info("   â”œâ”€ Turbo      - 18åˆ†  (4æ­¥+4å¹€)           å¿«é€Ÿé è¦½")
        logger.info("   â””â”€ Fast       - 35åˆ†  (6æ­¥+7å¹€)           æ¸¬è©¦æ¨è–¦ â˜…")
        logger.info("")
        logger.info("   â­ æ—¥å¸¸ä½¿ç”¨:")
        logger.info("   â””â”€ Balanced   - 50åˆ†  (7æ­¥+8å¹€)           å“è³ªé€Ÿåº¦æœ€ä½³ â˜…â˜…â˜…")
        logger.info("")
        logger.info("   ğŸ¨ é«˜å“è³ª:")
        logger.info("   â”œâ”€ High       - 70åˆ†  (8æ­¥+9å¹€)           ç´°ç¯€è±å¯Œ")
        logger.info("   â””â”€ Ultra      - 120åˆ† (720P 8æ­¥+9å¹€)      åŸç”Ÿé«˜æ¸…")
        logger.info("")
        logger.info("   ğŸ’¡ æ”¯æ´è‡ªè¨‚é…ç½®: å‚³å…¥å­—å…¸å³å¯è¦†è“‹é è¨­åƒæ•¸")
        logger.info("=" * 80)
    
    def load_models(self):
        """è¼‰å…¥æ¨¡å‹ï¼ˆå•Ÿå‹•æ™‚èª¿ç”¨ï¼‰"""
        if self.loaded:
            return
        
        logger.info("=" * 80)
        logger.info("ğŸš€ è¼‰å…¥æ¨¡å‹ï¼ˆæœ€çµ‚å„ªåŒ–ç‰ˆ v7.1ï¼‰...")
        logger.info("=" * 80)
        
        try:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                import gc
                gc.collect()
            
            logger.info("ğŸ“¥ è¼‰å…¥ wav2vec2...")
            self.wav2vec_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
                self.wav2vec_dir
            )
            # Force eager attention to support output_attentions=True
            self.audio_encoder = Wav2Vec2Model.from_pretrained(
                self.wav2vec_dir,
                attn_implementation='eager'
            ).to(self.device)
            logger.info("âœ… wav2vec2 å®Œæˆ")
            
            logger.info("ğŸ“¥ è¼‰å…¥ InfiniteTalk...")
            logger.info(f"   LoRA: {os.path.basename(self.lora_dir)}")
            logger.info(f"   LoRA Scale: 1.0")
            logger.info(f"   Text Guide: 1.0 (ä½¿ç”¨ LoRA)")
            logger.info(f"   Audio Guide: 2.0 (ä½¿ç”¨ LoRA)")
            logger.info(f"   è§£æåº¦: 480P / 720P")
            logger.info(f"   åŠ é€Ÿæ–¹å¼: é™ä½ steps/framesï¼ˆç©©å®šå¯é ï¼‰")
            logger.info(f"   VRAM ç®¡ç†: å•Ÿç”¨ (num_persistent=0)")
            
            cfg = WAN_CONFIGS['infinitetalk-14B']

            # ç¢ºä¿ LoRA æª”æ¡ˆå­˜åœ¨ï¼ˆå¿…é ˆä½¿ç”¨ï¼‰
            # LoRA ä¸‹è¼‰ä¾†æº: https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX
            # æª”æ¡ˆ: Wan2.1_I2V_14B_FusionX_LoRA.safetensors (353.9 MB)
            if not os.path.exists(self.lora_dir):
                raise FileNotFoundError(
                    f"âŒ LoRA æª”æ¡ˆä¸å­˜åœ¨: {self.lora_dir}\n"
                    f"è«‹å…ˆä¸‹è¼‰ LoRA æª”æ¡ˆåˆ° weights/ ç›®éŒ„\n"
                    f"ä¸‹è¼‰ä¾†æº: https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX\n"
                    f"æª”æ¡ˆåç¨±: Wan2.1_I2V_14B_FusionX_LoRA.safetensors (353.9 MB)"
                )

            self.wan_i2v = wan.InfiniteTalkPipeline(
                config=cfg,
                checkpoint_dir=self.ckpt_dir,
                device_id=0,
                rank=0,
                lora_dir=[self.lora_dir],
                lora_scales=[1.0],
                infinitetalk_dir=self.infinitetalk_dir
            )
            
            self.wan_i2v.vram_management = True
            self.wan_i2v.enable_vram_management(num_persistent_param_in_dit=0)
            
            logger.info("âœ… InfiniteTalk å®Œæˆ")
            self.loaded = True
            
            if torch.cuda.is_available():
                allocated = torch.cuda.memory_allocated() / (1024**3)
                reserved = torch.cuda.memory_reserved() / (1024**3)
                total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                free = total - allocated
                logger.info(f"ğŸ“Š GPU é¡¯å­˜: {allocated:.1f}GB ä½¿ç”¨ / {free:.1f}GB å¯ç”¨ / {total:.1f}GB ç¸½é‡")
            
            logger.info("=" * 80)
            logger.info("ğŸ‰ æ¨¡å‹å·²å¸¸é§ï¼ (æœ€çµ‚å„ªåŒ–ç‰ˆ v7.1)")
            logger.info("=" * 80)
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def extend_audio(self, audio_path, motion_frame=9):
        """å»¶é•·éŸ³é »"""
        try:
            audio_data, sample_rate = sf.read(audio_path)
            min_duration = (motion_frame / 8.0) + 0.5
            min_samples = int(min_duration * sample_rate)
            current_duration = len(audio_data) / sample_rate
            
            logger.info(f"ğŸµ éŸ³é »: {current_duration:.2f}ç§’")
            
            if len(audio_data) < min_samples:
                repeat_times = int(np.ceil(min_samples / len(audio_data)))
                audio_data = np.tile(audio_data, repeat_times)[:min_samples]
                sf.write(audio_path, audio_data, sample_rate)
                logger.info(f"âœ… å»¶é•·è‡³ {len(audio_data)/sample_rate:.2f}ç§’")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »è™•ç†å¤±æ•—: {e}")
            return False
    
    def _parse_quality_config(self, quality):
        """
        è§£æå“è³ªé…ç½®
        æ”¯æ´å…©ç¨®æ ¼å¼:
        1. å­—ä¸²: 'fast', 'balanced' ç­‰é è¨­é…ç½®
        2. å­—å…¸: è‡ªè¨‚é…ç½®åƒæ•¸
        
        è¿”å›: (preset_dict, config_type, config_name)
        """
        # åˆ¤æ–·æ˜¯å­—å…¸é‚„æ˜¯å­—ä¸²
        if isinstance(quality, dict):
            logger.info("ğŸ”§ ä½¿ç”¨è‡ªè¨‚é…ç½®ï¼ˆå­—å…¸æ ¼å¼ï¼‰")
            
            # å¿…è¦åƒæ•¸æª¢æŸ¥
            required_params = ['sampling_steps', 'motion_frame']
            missing_params = [p for p in required_params if p not in quality]
            
            if missing_params:
                raise ValueError(f"âŒ è‡ªè¨‚é…ç½®ç¼ºå°‘å¿…è¦åƒæ•¸: {missing_params}")
            
            # è¨­å®šé è¨­å€¼
            preset = {
                'resolution': quality.get('resolution', '480'),
                'sampling_steps': quality['sampling_steps'],
                'motion_frame': quality['motion_frame'],
                'mode': quality.get('mode', 'streaming'),
                'est_time': quality.get('est_time', 'æœªçŸ¥'),
                'description': quality.get('description', 'è‡ªè¨‚é…ç½®')
            }
            
            return preset, 'custom', 'custom'
            
        elif isinstance(quality, str):
            logger.info(f"ğŸ“‹ ä½¿ç”¨é è¨­é…ç½®: '{quality}'")
            
            if quality not in QUALITY_PRESETS:
                logger.warning(f"âš ï¸  æœªçŸ¥å“è³ª '{quality}'ï¼Œä½¿ç”¨ balanced")
                quality = 'balanced'
            
            return QUALITY_PRESETS[quality], 'preset', quality
            
        else:
            raise TypeError(f"âŒ quality åƒæ•¸é¡å‹éŒ¯èª¤: {type(quality)}ï¼Œæ‡‰ç‚º str æˆ– dict")
    
    def generate(self, 
                 image_path, 
                 audio_path, 
                 prompt,
                 output_path,
                 quality='balanced',
                 **kwargs):
        """
        çµ±ä¸€ç”Ÿæˆæ¥å£
        
        åƒæ•¸:
            quality: str æˆ– dict
                - str: é è¨­é…ç½®åç¨± ('ultra_fast', 'turbo', 'fast', 'balanced', 'high', 'ultra')
                - dict: è‡ªè¨‚é…ç½®ï¼Œå¿…é ˆåŒ…å«:
                    - sampling_steps (å¿…è¦): int, æ¡æ¨£æ­¥æ•¸
                    - motion_frame (å¿…è¦): int, å‹•ä½œå¹€æ•¸
                    - resolution (å¯é¸): str, '480' æˆ– '720', é è¨­ '480'
                    - mode (å¯é¸): str, é è¨­ 'streaming'
                    - est_time (å¯é¸): str, é ä¼°æ™‚é–“èªªæ˜
                    - description (å¯é¸): str, é…ç½®æè¿°
        
        ç¯„ä¾‹:
            # ä½¿ç”¨é è¨­é…ç½®
            generate(..., quality='fast')
            
            # ä½¿ç”¨è‡ªè¨‚é…ç½®
            generate(..., quality={
                'sampling_steps': 5,
                'motion_frame': 6,
                'resolution': '480',
                'description': 'è‡ªè¨‚å¿«é€Ÿé…ç½®'
            })
        """
        
        if not self.loaded:
            raise Exception("æ¨¡å‹æœªè¼‰å…¥ï¼è«‹ç¢ºä¿å·²èª¿ç”¨ load_models()")
        
        # è§£æé…ç½®
        try:
            preset, config_type, config_name = self._parse_quality_config(quality)
        except (ValueError, TypeError) as e:
            logger.error(str(e))
            raise
        
        # æå–åƒæ•¸
        resolution = preset['resolution']
        sample_steps = preset['sampling_steps']
        motion_frame = preset['motion_frame']
        mode = preset['mode']
        est_time = preset.get('est_time', 'æœªçŸ¥')
        description = preset.get('description', 'è‡ªè¨‚é…ç½®')
        
        # é¡¯ç¤ºé…ç½®è³‡è¨Š
        logger.info("=" * 80)
        if config_type == 'custom':
            logger.info(f"ğŸ¨ è‡ªè¨‚é…ç½®")
        else:
            logger.info(f"ğŸ¨ {config_name.upper()}")
        logger.info(f"   {description}")
        logger.info(f"   åƒæ•¸: {resolution}P, {sample_steps}æ­¥, {motion_frame}å¹€, mode={mode}")
        logger.info(f"   é ä¼°æ™‚é–“: {est_time}")
        logger.info("=" * 80)
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            import gc
            gc.collect()
        
        try:
            if not self.extend_audio(audio_path, motion_frame):
                raise Exception("éŸ³é »è™•ç†å¤±æ•—")
            
            temp_dir = f"temp_gen_{os.path.basename(output_path)}"
            os.makedirs(temp_dir, exist_ok=True)
            
            logger.info("ğŸµ è™•ç†éŸ³é »...")
            human_speech = audio_prepare_single(audio_path)
            sum_audio = os.path.join(temp_dir, 'audio.wav')
            sf.write(sum_audio, human_speech, 16000)
            
            audio_duration = len(human_speech) / 16000
            
            logger.info("ğŸ¤ æå–ç‰¹å¾µ...")
            audio_embedding = get_embedding(
                human_speech, 
                self.wav2vec_feature_extractor, 
                self.audio_encoder,
                device='cuda'
            )
            
            actual_audio_frames = audio_embedding.shape[0]
            max_frames = actual_audio_frames + 20
            
            logger.info(f"ğŸ“Š éŸ³é »: {audio_duration:.2f}ç§’, {actual_audio_frames}å¹€")
            logger.info(f"ğŸ“Š æœ€å¤§å¹€æ•¸: {max_frames} (ç´„ {max_frames/25:.1f}ç§’)")
            
            emb_path = os.path.join(temp_dir, 'audio_emb.pt')
            torch.save(audio_embedding, emb_path)
            
            input_clip = {
                'prompt': prompt,
                'cond_video': image_path,
                'cond_audio': {'person1': emb_path},
                'video_audio': sum_audio
            }
            
            # ç°¡æ½”ç©©å®šçš„é…ç½®
            extra_args = SimpleNamespace(
                use_teacache=False,
                teacache_thresh=1.0,
                use_apg=False,
                audio_mode='localfile',
                scene_seg=False,
                size=1.0
            )
            
            logger.info(f"ğŸš€ é–‹å§‹ç”Ÿæˆ ({resolution}P, {mode} æ¨¡å¼)...")
            
            import time
            start_time = time.time()
            
            video = self.wan_i2v.generate_infinitetalk(
                input_clip,
                size_buckget=f'infinitetalk-{resolution}',
                motion_frame=motion_frame,
                shift=2,
                sampling_steps=sample_steps,
                text_guide_scale=1.0,
                audio_guide_scale=2.0,
                seed=0,
                offload_model=False,
                max_frames_num=max_frames,
                color_correction_strength=0.0,
                extra_args=extra_args
            )
            
            elapsed_time = time.time() - start_time
            
            if hasattr(video, 'shape'):
                actual_frames = video.shape[2] if len(video.shape) > 2 else 0
                logger.info(f"ğŸ“¹ ç”Ÿæˆ: {actual_frames}å¹€ ({actual_frames/25:.1f}ç§’)")
            
            logger.info(f"â±ï¸  å¯¦éš›è€—æ™‚: {elapsed_time/60:.1f}åˆ†é˜ (é ä¼°: {est_time})")
            
            logger.info("ğŸ’¾ ä¿å­˜...")
            save_video_ffmpeg(video, output_path, [sum_audio], high_quality_save=False)
            
            final_path = f"{output_path}.mp4"
            
            if os.path.exists(final_path):
                result = subprocess.run(
                    ['ffprobe', '-v', 'error', '-show_entries', 
                     'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1', 
                     final_path],
                    capture_output=True,
                    text=True
                )
                if result.returncode == 0:
                    video_duration = float(result.stdout.strip())
                    logger.info(f"âœ… è¦–é »: {video_duration:.2f}ç§’ / éŸ³é »: {audio_duration:.2f}ç§’")
            
            import shutil
            shutil.rmtree(temp_dir, ignore_errors=True)
            
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
            
            logger.info(f"âœ… å®Œæˆ: {final_path}")
            if config_type == 'custom':
                logger.info(f"ğŸ“Š æ€§èƒ½çµ±è¨ˆ: è‡ªè¨‚é…ç½® ({sample_steps}æ­¥+{motion_frame}å¹€)ï¼Œ{elapsed_time/60:.1f}åˆ†é˜")
            else:
                logger.info(f"ğŸ“Š æ€§èƒ½çµ±è¨ˆ: {config_name} æ¨¡å¼ï¼Œ{elapsed_time/60:.1f}åˆ†é˜")
            
            return final_path
            
        except torch.cuda.OutOfMemoryError as e:
            logger.error(f"âŒ é¡¯å­˜ä¸è¶³!")
            if torch.cuda.is_available():
                allocated = torch.cuda.memory_allocated() / (1024**3)
                logger.error(f"   ç•¶å‰ä½¿ç”¨: {allocated:.1f}GB")
            logger.error("ğŸ’¡ è§£æ±ºæ–¹æ¡ˆ:")
            logger.error("   1. ä½¿ç”¨æ›´ä½å“è³ª: ultra_fast/turbo/fast")
            logger.error("   2. é™ä½è§£æåº¦: ultra â†’ balanced (720P â†’ 480P)")
            logger.error("   3. é™ä½è‡ªè¨‚åƒæ•¸: sampling_steps å’Œ motion_frame")
            logger.error("   4. æª¢æŸ¥å…¶ä»–é€²ç¨‹: nvidia-smi")
            torch.cuda.empty_cache()
            raise
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            raise

_model_instance = None

def get_model_service():
    global _model_instance
    if _model_instance is None:
        _model_instance = InfiniteTalkModelService()
        _model_instance.load_models()
    return _model_instance

if __name__ == "__main__":
    service = get_model_service()
    print("âœ… æœå‹™å°±ç·’ - æœ€çµ‚å„ªåŒ–ç‰ˆ v7.1")
    print("")
    print("ğŸ“Š ä½¿ç”¨æ–¹å¼:")
    print("")
    print("1ï¸âƒ£  é è¨­é…ç½®ï¼ˆå­—ä¸²ï¼‰:")
    print("   service.generate(..., quality='fast')")
    print("")
    print("2ï¸âƒ£  è‡ªè¨‚é…ç½®ï¼ˆå­—å…¸ï¼‰:")
    print("   service.generate(..., quality={")
    print("       'sampling_steps': 5,")
    print("       'motion_frame': 6,")
    print("       'resolution': '480',  # å¯é¸")
    print("       'description': 'æˆ‘çš„é…ç½®'  # å¯é¸")
    print("   })")
    print("")
    print("ğŸ“‹ é è¨­é…ç½®:")
    print("   ultra_fast / turbo / fast / balanced / high / ultra")
