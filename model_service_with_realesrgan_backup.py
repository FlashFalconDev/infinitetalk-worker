"""
InfiniteTalk æ¨¡å‹æœå‹™ - æ”¯æ´å¤šè§£æåº¦ AI å‡é »
å“è³ªæ–¹æ¡ˆï¼š
- Standard: 480P (å¿«é€Ÿ) - 70åˆ†é˜
- Premium: 480P (é«˜å“è³ª) - 120åˆ†é˜
- Ultra: 720P (Premium + AIå‡é ») - 135åˆ†é˜
- Supreme: 1080P (Premium + å…©æ®µAIå‡é ») - 155åˆ†é˜
å‡é »å„ªå…ˆç´šï¼šReal-ESRGAN > FFmpeg > Topaz (å¯é¸)
"""
import torch
import os
import sys
import logging
import soundfile as sf
import numpy as np
import subprocess
from types import SimpleNamespace

sys.path.insert(0, '/workspace/InfiniteTalk')

import wan
from src.audio_analysis.wav2vec2 import Wav2Vec2Model
from transformers import Wav2Vec2FeatureExtractor
from wan.utils.multitalk_utils import save_video_ffmpeg
from wan.configs import WAN_CONFIGS
from generate_infinitetalk import audio_prepare_single, get_embedding

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

QUALITY_PRESETS = {
    'standard': {
        'resolution': '480',
        'sampling_steps': 6,        # å¿«é€Ÿåƒæ•¸
        'motion_frame': 7,          # å¿«é€Ÿåƒæ•¸
        'use_teacache': False,
        'teacache_thresh': 1.0,
        'upscale': False,
        'description': 'æ¨™æº–å“è³ª 480P (å¿«é€Ÿ)'
    },
    'premium': {
        'resolution': '480',
        'sampling_steps': 8,        # é«˜å“è³ªåƒæ•¸
        'motion_frame': 9,          # é«˜å“è³ªåƒæ•¸
        'use_teacache': False,
        'teacache_thresh': 1.0,
        'upscale': False,
        'description': 'é«˜å“è³ª 480P'
    },
    'ultra': {
        'resolution': '480',
        'sampling_steps': 8,        # Premium åƒæ•¸
        'motion_frame': 9,          # Premium åƒæ•¸
        'use_teacache': False,
        'teacache_thresh': 1.0,
        'upscale': True,
        'target_resolution': '720',
        'upscale_stages': 1,        # å–®æ®µå‡é »
        'description': 'è¶…é«˜å“è³ª 720P (Premium + AIå‡é »)'
    },
    'supreme': {
        'resolution': '480',
        'sampling_steps': 8,        # Premium åƒæ•¸
        'motion_frame': 9,          # Premium åƒæ•¸
        'use_teacache': False,
        'teacache_thresh': 1.0,
        'upscale': True,
        'target_resolution': '1080',
        'upscale_stages': 2,        # å…©æ®µå¼å‡é »
        'description': 'æ¥µè‡´å“è³ª 1080P (Premium + å…©æ®µAIå‡é »)'
    }
}

class InfiniteTalkModelService:
    def __init__(self, 
                 ckpt_dir='weights/Wan2.1-I2V-14B-480P',
                 wav2vec_dir='weights/chinese-wav2vec2-base',
                 infinitetalk_dir='weights/InfiniteTalk/single/infinitetalk.safetensors',
                 lora_dir='weights/Wan2.1_I2V_14B_FusionX_LoRA.safetensors',
                 device='cuda',
                 realesrgan_model='weights/realesr-animevideov3.pth',
                 topaz_path='/usr/local/bin/tvai-cli'):
        
        self.ckpt_dir = ckpt_dir
        self.wav2vec_dir = wav2vec_dir
        self.infinitetalk_dir = infinitetalk_dir
        self.lora_dir = lora_dir
        self.device = device
        self.realesrgan_model = realesrgan_model
        self.topaz_path = topaz_path
        
        self.loaded = False
        self.wan_i2v = None
        self.wav2vec_feature_extractor = None
        self.audio_encoder = None
        
        # æª¢æŸ¥å„ç¨®å‡é »å·¥å…·çš„å¯ç”¨æ€§
        self.realesrgan_available = self._check_realesrgan()
        self.ffmpeg_available = self._check_ffmpeg()
        self.topaz_available = self._check_topaz()
        
        # é¡¯ç¤ºå¯ç”¨çš„å‡é »æ–¹æ¡ˆ
        self._display_upscale_options()
        
    def _check_realesrgan(self):
        """æª¢æŸ¥ Real-ESRGAN æ˜¯å¦å¯ç”¨"""
        try:
            import cv2
            from basicsr.archs.rrdbnet_arch import RRDBNet
            from realesrgan import RealESRGANer
            
            if os.path.exists(self.realesrgan_model):
                logger.info(f"âœ… Real-ESRGAN å¯ç”¨ (ä¸»åŠ›å‡é »æ–¹æ¡ˆ)")
                return True
            else:
                logger.warning(f"âš ï¸  Real-ESRGAN æ¨¡å‹ä¸å­˜åœ¨: {self.realesrgan_model}")
                logger.info(f"   è«‹ä¸‹è¼‰: wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.5.0/realesr-animevideov3.pth -P weights/")
                return False
        except ImportError as e:
            logger.warning(f"âš ï¸  Real-ESRGAN æœªå®‰è£: {e}")
            logger.info(f"   è«‹å®‰è£: pip install realesrgan basicsr facexlib gfpgan opencv-python")
            return False
    
    def _check_ffmpeg(self):
        """æª¢æŸ¥ FFmpeg æ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                ['ffmpeg', '-version'],
                capture_output=True,
                text=True,
                timeout=5
            )
            if result.returncode == 0:
                logger.info(f"âœ… FFmpeg å¯ç”¨ (å‚™ç”¨å‡é »æ–¹æ¡ˆ)")
                return True
        except Exception as e:
            logger.error(f"âŒ FFmpeg ä¸å¯ç”¨: {e}")
        return False
    
    def _check_topaz(self):
        """æª¢æŸ¥ Topaz Video AI æ˜¯å¦å¯ç”¨ï¼ˆå¯é¸ï¼‰"""
        try:
            result = subprocess.run(
                [self.topaz_path, '--version'],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode == 0:
                logger.info(f"âœ… Topaz Video AI å¯ç”¨ (å¯é¸é«˜ç´šæ–¹æ¡ˆ)")
                return True
        except Exception:
            pass
        return False
    
    def _display_upscale_options(self):
        """é¡¯ç¤ºå¯ç”¨çš„å‡é »é¸é …"""
        logger.info("=" * 70)
        logger.info("ğŸ“Š å‡é »æ–¹æ¡ˆç‹€æ…‹:")
        
        options = []
        if self.realesrgan_available:
            options.append("Real-ESRGAN (AIå¢å¼·) â­â­â­â­â­")
        if self.ffmpeg_available:
            options.append("FFmpeg (å¿«é€Ÿç©©å®š) â­â­â­â­")
        if self.topaz_available:
            options.append("Topaz (é ‚ç´šå“è³ª) â­â­â­â­â­")
        
        if options:
            for opt in options:
                logger.info(f"   âœ… {opt}")
        else:
            logger.error("   âŒ æ²’æœ‰å¯ç”¨çš„å‡é »æ–¹æ¡ˆï¼")
        
        logger.info("=" * 70)
    
    def upscale_video_realesrgan(self, input_path, output_path, target_height=720):
        """ä½¿ç”¨ Real-ESRGAN AI å‡é »"""
        try:
            logger.info(f"ğŸ” ä½¿ç”¨ Real-ESRGAN AI å‡é »åˆ° {target_height}P...")
            
            from basicsr.archs.rrdbnet_arch import RRDBNet
            from realesrgan import RealESRGANer
            from realesrgan.archs.srvgg_arch import SRVGGNetCompact
            import cv2
            
            # è¨ˆç®—ç¸®æ”¾å€æ•¸
            probe_cmd = [
                'ffprobe', '-v', 'error',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=height',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                input_path
            ]
            result = subprocess.run(probe_cmd, capture_output=True, text=True)
            current_height = int(result.stdout.strip())
            scale = target_height / current_height
            
            logger.info(f"   åŸé«˜åº¦: {current_height}P â†’ ç›®æ¨™: {target_height}P (ç¸®æ”¾: {scale:.2f}x)")
            
            # åˆå§‹åŒ– Real-ESRGAN
            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, 
                           num_block=23, num_grow_ch=32, scale=2)
            
            upsampler = RealESRGANer(
                scale=2,
                model_path=self.realesrgan_model,
                model=model,
                tile=400,
                tile_pad=10,
                pre_pad=0,
                half=True,
                device=self.device
            )
            
            # æå–è¦–é »å¹€
            temp_dir = f"temp_realesrgan_{os.path.basename(input_path)}"
            os.makedirs(temp_dir, exist_ok=True)
            frames_dir = os.path.join(temp_dir, 'frames')
            output_frames_dir = os.path.join(temp_dir, 'output_frames')
            os.makedirs(frames_dir, exist_ok=True)
            os.makedirs(output_frames_dir, exist_ok=True)
            
            # æå–å¹€
            logger.info(f"   ğŸ“¹ æå–è¦–é »å¹€...")
            extract_cmd = [
                'ffmpeg', '-i', input_path,
                '-qscale:v', '1', '-qmin', '1', '-qmax', '1',
                '-vsync', '0',
                f'{frames_dir}/frame_%08d.png'
            ]
            subprocess.run(extract_cmd, capture_output=True, timeout=120)
            
            # è™•ç†æ¯ä¸€å¹€
            frame_files = sorted([f for f in os.listdir(frames_dir) if f.endswith('.png')])
            total_frames = len(frame_files)
            logger.info(f"   ğŸ¬ é–‹å§‹è™•ç† {total_frames} å¹€...")
            
            for i, frame_file in enumerate(frame_files, 1):
                if i % 10 == 0 or i == total_frames:
                    logger.info(f"   è™•ç†é€²åº¦: {i}/{total_frames} ({i*100//total_frames}%)")
                
                frame_path = os.path.join(frames_dir, frame_file)
                output_frame_path = os.path.join(output_frames_dir, frame_file)
                
                img = cv2.imread(frame_path, cv2.IMREAD_UNCHANGED)
                output, _ = upsampler.enhance(img, outscale=scale)
                cv2.imwrite(output_frame_path, output)
            
            logger.info(f"   âœ… AI å‡é »å®Œæˆ")
            
            # é‡æ–°çµ„åˆè¦–é »
            logger.info(f"   ğŸï¸  é‡çµ„è¦–é »...")
            
            fps_cmd = [
                'ffprobe', '-v', 'error',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=r_frame_rate',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                input_path
            ]
            fps_result = subprocess.run(fps_cmd, capture_output=True, text=True)
            fps = fps_result.stdout.strip()
            
            combine_cmd = [
                'ffmpeg',
                '-framerate', fps,
                '-i', f'{output_frames_dir}/frame_%08d.png',
                '-i', input_path,
                '-map', '0:v',
                '-map', '1:a?',
                '-c:v', 'libx264',
                '-preset', 'slow',
                '-crf', '18',
                '-c:a', 'copy',
                '-pix_fmt', 'yuv420p',
                '-y',
                output_path
            ]
            
            result = subprocess.run(combine_cmd, capture_output=True, 
                                   text=True, timeout=300)
            
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            import shutil
            shutil.rmtree(temp_dir, ignore_errors=True)
            
            if result.returncode == 0 and os.path.exists(output_path):
                logger.info(f"âœ… Real-ESRGAN å‡é »å®Œæˆ")
                return True
            else:
                logger.error(f"âŒ è¦–é »çµ„åˆå¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Real-ESRGAN å‡é »éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def upscale_video_ffmpeg(self, input_path, output_path, target_height=720):
        """ä½¿ç”¨ FFmpeg Lanczos å‡é »ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            logger.info(f"ğŸ” ä½¿ç”¨ FFmpeg å‡é »åˆ° {target_height}P...")
            
            cmd = [
                'ffmpeg',
                '-i', input_path,
                '-vf', f'scale=-1:{target_height}:flags=lanczos',
                '-c:v', 'libx264',
                '-preset', 'slow',
                '-crf', '18',
                '-c:a', 'copy',
                '-y',
                output_path
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300
            )
            
            if result.returncode == 0 and os.path.exists(output_path):
                logger.info(f"âœ… FFmpeg å‡é »å®Œæˆ")
                return True
            else:
                logger.error(f"âŒ FFmpeg å‡é »å¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ FFmpeg å‡é »éŒ¯èª¤: {e}")
            return False
    
    def upscale_video_topaz(self, input_path, output_path, target_height=720):
        """ä½¿ç”¨ Topaz Video AI å‡é »ï¼ˆå¯é¸æ–¹æ¡ˆï¼‰"""
        try:
            logger.info(f"ğŸ” ä½¿ç”¨ Topaz AI å‡é »åˆ° {target_height}P...")
            
            probe_cmd = [
                'ffprobe', '-v', 'error',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=height',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                input_path
            ]
            result = subprocess.run(probe_cmd, capture_output=True, text=True)
            current_height = int(result.stdout.strip())
            scale = target_height / current_height
            
            cmd = [
                self.topaz_path,
                input_path,
                '--output', output_path,
                '--model', 'prob-3',
                '--scale', str(scale),
                '--device', '0',
                '--vcodec', 'h264',
                '--quality', 'high'
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=900
            )
            
            if result.returncode == 0 and os.path.exists(output_path):
                logger.info(f"âœ… Topaz å‡é »å®Œæˆ")
                return True
            else:
                logger.error(f"âŒ Topaz å‡é »å¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Topaz å‡é »éŒ¯èª¤: {e}")
            return False
    
    def upscale_video_single_stage(self, input_path, output_path, target_height):
        """å–®æ®µå‡é »ï¼ˆå„ªå…ˆç´šï¼šReal-ESRGAN > FFmpeg > Topazï¼‰"""
        logger.info(f"ğŸ“Š å–®æ®µå‡é »: 480P â†’ {target_height}P")
        
        # å„ªå…ˆä½¿ç”¨ Real-ESRGAN
        if self.realesrgan_available:
            if self.upscale_video_realesrgan(input_path, output_path, target_height):
                return True
            logger.warning("âš ï¸  Real-ESRGAN å¤±æ•—ï¼Œå˜—è©¦å‚™ç”¨æ–¹æ¡ˆ...")
        
        # å‚™ç”¨ï¼šFFmpeg
        if self.ffmpeg_available:
            if self.upscale_video_ffmpeg(input_path, output_path, target_height):
                return True
            logger.warning("âš ï¸  FFmpeg å¤±æ•—ï¼Œå˜—è©¦ Topaz...")
        
        # æœ€å¾Œï¼šTopazï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        if self.topaz_available:
            if self.upscale_video_topaz(input_path, output_path, target_height):
                return True
        
        logger.error("âŒ æ‰€æœ‰å‡é »æ–¹æ¡ˆéƒ½å¤±æ•—äº†")
        return False
    
    def upscale_video_two_stage(self, input_path, output_path):
        """å…©æ®µå¼å‡é »ï¼š480P â†’ 720P (AI) â†’ 1080P (FFmpeg)"""
        try:
            logger.info(f"ğŸ“Š å…©æ®µå¼å‡é »: 480P â†’ 720P â†’ 1080P")
            
            # ç¬¬ä¸€æ®µï¼š480P â†’ 720P (AI å¢å¼·)
            temp_720p = input_path.replace('.mp4', '_temp_720p.mp4')
            logger.info(f"   ğŸ¬ ç¬¬ä¸€æ®µ: 480P â†’ 720P (AIå¢å¼·)")
            
            # å„ªå…ˆä½¿ç”¨ Real-ESRGAN
            stage1_success = False
            if self.realesrgan_available:
                stage1_success = self.upscale_video_realesrgan(input_path, temp_720p, 720)
            
            if not stage1_success and self.topaz_available:
                logger.warning("   âš ï¸  Real-ESRGAN å¤±æ•—ï¼Œå˜—è©¦ Topaz...")
                stage1_success = self.upscale_video_topaz(input_path, temp_720p, 720)
            
            if not stage1_success and self.ffmpeg_available:
                logger.warning("   âš ï¸  AIæ–¹æ¡ˆå¤±æ•—ï¼Œé™ç´šä½¿ç”¨ FFmpeg...")
                stage1_success = self.upscale_video_ffmpeg(input_path, temp_720p, 720)
            
            if not stage1_success:
                logger.error("   âŒ ç¬¬ä¸€æ®µå‡é »å¤±æ•—")
                return False
            
            logger.info(f"   âœ… ç¬¬ä¸€æ®µå®Œæˆ")
            
            # ç¬¬äºŒæ®µï¼š720P â†’ 1080P (è¼•åº¦æ”¾å¤§)
            logger.info(f"   ğŸ¬ ç¬¬äºŒæ®µ: 720P â†’ 1080P (è¼•åº¦æ”¾å¤§)")
            
            cmd = [
                'ffmpeg',
                '-i', temp_720p,
                '-vf', 'scale=-1:1080:flags=lanczos',
                '-c:v', 'libx264',
                '-preset', 'medium',
                '-crf', '20',
                '-c:a', 'copy',
                '-y',
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, 
                                   text=True, timeout=300)
            
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if os.path.exists(temp_720p):
                os.remove(temp_720p)
            
            if result.returncode == 0 and os.path.exists(output_path):
                logger.info(f"   âœ… ç¬¬äºŒæ®µå®Œæˆ")
                logger.info(f"âœ… å…©æ®µå¼å‡é »å®Œæˆï¼")
                return True
            else:
                logger.error(f"   âŒ ç¬¬äºŒæ®µå¤±æ•—: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ å…©æ®µå¼å‡é »éŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def upscale_video(self, input_path, output_path, target_height=720, stages=1):
        """æ™ºèƒ½å‡é »å…¥å£"""
        if stages == 1:
            return self.upscale_video_single_stage(input_path, output_path, target_height)
        elif stages == 2:
            return self.upscale_video_two_stage(input_path, output_path)
        else:
            logger.error(f"âŒ ä¸æ”¯æ´çš„å‡é »éšæ®µæ•¸: {stages}")
            return False
    
    def load_models(self):
        if self.loaded:
            return
        
        logger.info("=" * 70)
        logger.info("ğŸš€ è¼‰å…¥æ¨¡å‹...")
        logger.info("=" * 70)
        
        try:
            logger.info("ğŸ“¥ wav2vec2...")
            self.wav2vec_feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(
                self.wav2vec_dir
            )
            self.audio_encoder = Wav2Vec2Model.from_pretrained(
                self.wav2vec_dir
            ).to(self.device)
            logger.info("âœ… wav2vec2")
            
            logger.info("ğŸ“¥ InfiniteTalk...")
            cfg = WAN_CONFIGS['infinitetalk-14B']
            
            self.wan_i2v = wan.InfiniteTalkPipeline(
                config=cfg,
                checkpoint_dir=self.ckpt_dir,
                device_id=0,
                rank=0,
                lora_dir=[self.lora_dir],
                lora_scales=[1.0],
                infinitetalk_dir=self.infinitetalk_dir
            )
            
            self.wan_i2v.vram_management = True
            self.wan_i2v.enable_vram_management(num_persistent_param_in_dit=0)
            
            logger.info("âœ… InfiniteTalk")
            self.loaded = True
            logger.info("=" * 70)
            logger.info("ğŸ‰ æ¨¡å‹å·²å¸¸é§!")
            logger.info("=" * 70)
            
        except Exception as e:
            logger.error(f"âŒ å¤±æ•—: {e}")
            raise
    
    def extend_audio(self, audio_path, motion_frame=9):
        try:
            audio_data, sample_rate = sf.read(audio_path)
            min_duration = (motion_frame / 8.0) + 0.5
            min_samples = int(min_duration * sample_rate)
            current_duration = len(audio_data) / sample_rate
            
            logger.info(f"ğŸµ éŸ³é »: {current_duration:.2f}ç§’")
            
            if len(audio_data) < min_samples:
                repeat_times = int(np.ceil(min_samples / len(audio_data)))
                audio_data = np.tile(audio_data, repeat_times)[:min_samples]
                sf.write(audio_path, audio_data, sample_rate)
                logger.info(f"âœ… å·²å»¶é•·éŸ³é »è‡³ {len(audio_data)/sample_rate:.2f}ç§’")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »è™•ç†å¤±æ•—: {e}")
            return False
    
    def generate(self, 
                 image_path, 
                 audio_path, 
                 prompt,
                 output_path,
                 quality='standard',
                 resolution=None,
                 sample_steps=None,
                 motion_frame=None):
        if not self.loaded:
            self.load_models()
        
        logger.info(f"ğŸ” æ”¶åˆ°å“è³ª: '{quality}'")
        
        if quality in QUALITY_PRESETS:
            logger.info(f"âœ… æ‰¾åˆ°å“è³ªé è¨­")
            preset = QUALITY_PRESETS[quality]
            resolution = resolution or preset['resolution']
            sample_steps = sample_steps or preset['sampling_steps']
            motion_frame = motion_frame or preset['motion_frame']
            use_teacache = preset['use_teacache']
            teacache_thresh = preset['teacache_thresh']
            need_upscale = preset.get('upscale', False)
            target_resolution = preset.get('target_resolution', '480')
            upscale_stages = preset.get('upscale_stages', 1)
            
            logger.info(f"ğŸ¨ ä½¿ç”¨å“è³ª: {quality}")
            logger.info(f"   èªªæ˜: {preset['description']}")
            logger.info(f"   ç”Ÿæˆè§£æåº¦: {resolution}P")
            logger.info(f"   æ¡æ¨£æ­¥æ•¸: {sample_steps}")
            logger.info(f"   å‹•ä½œå¹€: {motion_frame}")
            if need_upscale:
                logger.info(f"   âœ¨ å°‡å‡é »è‡³: {target_resolution}P")
                logger.info(f"   ğŸ“Š å‡é »éšæ®µ: {upscale_stages} æ®µ")
        else:
            logger.warning(f"âš ï¸ å“è³ª '{quality}' ä¸åœ¨é è¨­ä¸­ï¼Œä½¿ç”¨ standard")
            quality = 'standard'
            preset = QUALITY_PRESETS['standard']
            resolution = preset['resolution']
            sample_steps = preset['sampling_steps']
            motion_frame = preset['motion_frame']
            use_teacache = preset['use_teacache']
            teacache_thresh = preset['teacache_thresh']
            need_upscale = False
        
        logger.info(f"ğŸ¬ {output_path}")
        
        try:
            if not self.extend_audio(audio_path, motion_frame):
                raise Exception("éŸ³é »è™•ç†å¤±æ•—")
            
            temp_dir = f"temp_gen_{os.path.basename(output_path)}"
            os.makedirs(temp_dir, exist_ok=True)
            
            logger.info("ğŸµ è™•ç†éŸ³é »...")
            human_speech = audio_prepare_single(audio_path)
            sum_audio = os.path.join(temp_dir, 'audio.wav')
            sf.write(sum_audio, human_speech, 16000)
            
            audio_duration = len(human_speech) / 16000
            
            logger.info("ğŸ¤ æå–ç‰¹å¾µ...")
            audio_embedding = get_embedding(
                human_speech, 
                self.wav2vec_feature_extractor, 
                self.audio_encoder,
                device='cuda'
            )
            
            actual_audio_frames = audio_embedding.shape[0]
            max_frames = actual_audio_frames + 20
            
            logger.info(f"ğŸ“Š éŸ³é »æ™‚é•·: {audio_duration:.2f}ç§’")
            logger.info(f"ğŸ“Š Audio embedding å¹€æ•¸: {actual_audio_frames}")
            logger.info(f"ğŸ“Š è¨­å®šæœ€å¤§å¹€æ•¸: {max_frames}")
            
            emb_path = os.path.join(temp_dir, 'audio_emb.pt')
            torch.save(audio_embedding, emb_path)
            
            input_clip = {
                'prompt': prompt,
                'cond_video': image_path,
                'cond_audio': {'person1': emb_path},
                'video_audio': sum_audio
            }
            
            extra_args = SimpleNamespace(
                use_teacache=use_teacache,
                teacache_thresh=teacache_thresh,
                use_apg=False,
                audio_mode='localfile',
                scene_seg=False,
                size=1.0
            )
            
            logger.info(f"ğŸš€ é–‹å§‹ç”Ÿæˆ (steps={sample_steps}, motion={motion_frame})...")
            
            video = self.wan_i2v.generate_infinitetalk(
                input_clip,
                size_buckget=f'infinitetalk-{resolution}',
                motion_frame=motion_frame,
                shift=2,
                sampling_steps=sample_steps,
                text_guide_scale=1.0,
                audio_guide_scale=2.0,
                seed=0,
                offload_model=False,
                max_frames_num=max_frames,
                color_correction_strength=0.0,
                extra_args=extra_args
            )
            
            if hasattr(video, 'shape'):
                actual_frames = video.shape[2] if len(video.shape) > 2 else 0
                actual_duration = actual_frames / 8.0
                logger.info(f"ğŸ“¹ ç”Ÿæˆ: {actual_frames} å¹€, {actual_duration:.2f}ç§’")
            
            logger.info("ğŸ’¾ ä¿å­˜ 480P...")
            save_video_ffmpeg(video, output_path, [sum_audio], high_quality_save=False)
            
            video_480p_path = f"{output_path}.mp4"
            final_path = video_480p_path
            
            # å‡é »è™•ç†
            if need_upscale and os.path.exists(video_480p_path):
                logger.info(f"âœ¨ é–‹å§‹å‡é »åˆ° {target_resolution}P...")
                
                if upscale_stages == 2:
                    # å…©æ®µå¼å‡é »
                    video_final_path = f"{output_path}_{target_resolution}p.mp4"
                    if self.upscale_video_two_stage(video_480p_path, video_final_path):
                        final_path = video_final_path
                        logger.info(f"âœ… å…©æ®µå¼å‡é »å®Œæˆ: {video_final_path}")
                    else:
                        logger.warning("âš ï¸  å‡é »å¤±æ•—ï¼Œä½¿ç”¨ 480P åŸæª”")
                else:
                    # å–®æ®µå‡é »
                    video_final_path = f"{output_path}_{target_resolution}p.mp4"
                    if self.upscale_video_single_stage(video_480p_path, video_final_path, 
                                                       int(target_resolution)):
                        final_path = video_final_path
                        logger.info(f"âœ… å‡é »å®Œæˆ: {video_final_path}")
                    else:
                        logger.warning("âš ï¸  å‡é »å¤±æ•—ï¼Œä½¿ç”¨ 480P åŸæª”")
            
            # é©—è­‰æœ€çµ‚è¦–é »
            if os.path.exists(final_path):
                result = subprocess.run(
                    ['ffprobe', '-v', 'error', '-show_entries', 
                     'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1', 
                     final_path],
                    capture_output=True,
                    text=True
                )
                if result.returncode == 0:
                    video_duration = float(result.stdout.strip())
                    logger.info(f"âœ… æœ€çµ‚è¦–é »: {video_duration:.2f}ç§’ / éŸ³é »: {audio_duration:.2f}ç§’")
                    
                    if abs(video_duration - audio_duration) > 2:
                        logger.warning(f"âš ï¸  é•·åº¦ä¸ç¬¦! å·®è·: {abs(video_duration - audio_duration):.2f}ç§’")
            
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            import shutil
            shutil.rmtree(temp_dir, ignore_errors=True)
            
            logger.info(f"âœ… å®Œæˆ: {final_path}")
            return final_path
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            raise

_model_instance = None

def get_model_service():
    global _model_instance
    if _model_instance is None:
        _model_instance = InfiniteTalkModelService()
        _model_instance.load_models()
    return _model_instance

if __name__ == "__main__":
    service = get_model_service()
    
    print("\n" + "="*70)
    print("æ¸¬è©¦ Standard (480P - å¿«é€Ÿ)")
    print("="*70)
    result = service.generate(
        image_path="examples/single/ref_image.png",
        audio_path="examples/single/1.wav",
        prompt="A woman speaking",
        output_path="test_standard",
        quality="standard"
    )
    print(f"âœ… Standard å®Œæˆ: {result}")
