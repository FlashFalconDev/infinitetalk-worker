version: '3.8'

services:
  infinitetalk-worker:
    build:
      context: .
      dockerfile: Dockerfile
    image: infinitetalk-worker:v7.2
    container_name: infinitetalk-worker-1
    
    # GPU 配置
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    # 環境變數
    environment:
      - INFINITETALK_API_BASE=${INFINITETALK_API_BASE:-https://host.flashfalcon.info}
      - INFINITETALK_WORKER_TOKEN=${INFINITETALK_WORKER_TOKEN}
      - WORKER_NAME=${WORKER_NAME:-docker-worker-01}
      - WORKER_REGION=${WORKER_REGION:-default}
      - CUDA_VISIBLE_DEVICES=0
    
    # 掛載目錄
    volumes:
      # 輸出目錄
      - ./outputs:/workspace/InfiniteTalk/outputs
      # 臨時目錄
      - ./temp_downloads:/workspace/InfiniteTalk/temp_downloads
      # 模型緩存（可選，避免重複下載）
      - ~/.cache/huggingface:/root/.cache/huggingface
    
    # 網路模式
    network_mode: bridge
    
    # 重啟策略
    restart: unless-stopped
    
    # 日誌配置
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# 如果要部署多個 Worker
  infinitetalk-worker-2:
    extends:
      service: infinitetalk-worker
    container_name: infinitetalk-worker-2
    environment:
      - INFINITETALK_API_BASE=${INFINITETALK_API_BASE:-https://host.flashfalcon.info}
      - INFINITETALK_WORKER_TOKEN=${INFINITETALK_WORKER_TOKEN_2}
      - WORKER_NAME=${WORKER_NAME_2:-docker-worker-02}
      - WORKER_REGION=${WORKER_REGION:-default}
      - CUDA_VISIBLE_DEVICES=1  # 使用第二張 GPU
    # 如果只有一張 GPU，註解掉這個 service
    profiles:
      - multi-gpu
